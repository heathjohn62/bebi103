{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t10_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Give an example of a situation where it is ok to throw out data you acquired.\n",
    "\n",
    "If I was collecting the number of divisions for 3 different strains of bacteria, and I forgot to label some of my samples (and couldn't identify them in any other way) it would be ok to throw those data points out, but this should be done before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "If you were to summarize the posterior with a MAP/error bar using optimization (not MCMC), would it be easier to use the Student-t method of dealing with outliers or the good/bad data model? Why?\n",
    "\n",
    "Student t likelihoods have very large tails. They both seem to work with regressions so I'm not sure which one would be better to use. The student t seems easier to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Describe in words the generative model behind the use of all three outlier methods discussed in the tutorial (median plugin estimate, Student-t likelihood, good-bad data model).\n",
    "\n",
    "Median plugin estimate: Ee know for the gaussian, the median approximates the mean and obviously the median is less affected by outliers. So, we can sample medians from the data. We used a bootstrap with a 95% confidence interval.\n",
    "\n",
    "Student-t likelihood: Model has heavier tails than the gaussian distributions so it better accounts for outliers. \n",
    "\n",
    "Good/bad data model: Assume that each point can be \"good\" or \"bad\" and depending on that distiction, assign it a different error bar measure."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
