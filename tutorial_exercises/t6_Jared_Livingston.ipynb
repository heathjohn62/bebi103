{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t6_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "What is the difference between the prior distribution and posterior distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prior distribution represents what we know about a parameter before looking at data, while the posterior distribution combines the prior distribution with the data to represent what we know about the parameter after looking at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Why are prior predictive checks an important step in the process of building a generative model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior predictive checks are important for building a generative model because they make sure that the generative model generates reasonable datasets that both reflect our intuitions and obey physical laws. Thus we are verifying that our generative model will not be invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Why is it necessary to compute summaries of the posterior? In other words, why can't we just write down the posterior (which is what the process of building a model is anyway) and be done with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure about this, but I think it is necessary to compute summaries of the posterior to better understand the meaning of the posterior in terms of interpreting it and checking inferences against it, which is easier with summaries than with the general shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "When performing parameter estimation by optimization, after we find the MAP, why do we locally approximate the posterior near the MAP as a (possibly multivariate) Gaussian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We locally approximate the posterior near the MAP as a Gaussian to make the posterior easier to work with so we can, for example, make error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
