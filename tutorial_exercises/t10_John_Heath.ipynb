{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t10_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Give an example of a situation where it is ok to throw out data you acquired.\n",
    "\n",
    "Suppose that I performed an optogenetics experiment, testing whether different neural circuits in c. elegans drove reversal of the worm movement when stimulated. However, after measuring the reversals in different strains, I found that the TAs who set up the experiment forgot to screen the worms for GFP, meaning that we weren't actually sure which worms had channelrhodopsins and which didn't. Then I would throw out the data, because I am not interested in the posterior from which I drew values (I don't care whether the mix of normal worms and worms with channelrhodopsins reversed, I only care whether specifically the worms with channelrhodopsins reversed). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "If you were to summarize the posterior with a MAP/error bar using optimization (not MCMC), would it be easier to use the Student-t method of dealing with outliers or the good/bad data model? Why?\n",
    "\n",
    "It would be easier to use the good/bad data model. If we were to use the Student-t model to obtain error bars, we would be taking a gaussian approximation about the MAP, and the effect of the (potentially) strong tails in the Student-t would be entirely lost. However, by explicitly encoding by the structure of the model that there will be some points that have a higher error, we can take a guassian approximation of all parameters in the good/bad data model and still have an accurate interpretation of the variability in the posterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Describe in words the generative model behind the use of all three outlier methods discussed in the tutorial (median plugin estimate, Student-t likelihood, good-bad data model).\n",
    "\n",
    "For the median plugin estimate, me assumed that the actual data approximated the posterior, and we sampled from the data to obtain medians. We used a sample size the size of the data to do this, and this is a bootstrap. In this case, the confidence interval would be the smallest continous range that caputures 95% of all medians sampled. \n",
    "\n",
    "When using the Student-t likelihood, we are fitting a model to the data that accounts for outliers by having heavier tails than the guassian. Based on the number and value of outliers, the model will be optimized to have tails between the cauchy distribution and the guassian distribution. \n",
    "\n",
    "The good/bad data model assues that there is some probability that a data point will be an outlier, and assigns a greater variance to outliers than that which is given to \"good\" data points. However, it still allows the priors on parameters that describe outliers to be guassian, since outliers are being explicitly described. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
