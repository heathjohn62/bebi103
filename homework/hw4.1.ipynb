{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits: \n",
    "John Heath wrote code and explanations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.1: Analysis of FRAP data (40 pts)\n",
    "\n",
    "Both problems in this homework set consist of the image processing portion of a greater inference problem. For this problem, you will perform image analysis of data from a fluorescence recovery after photobleaching (FRAP) experiment. The data set comes from [Nate Goehring](https://goehringlab.crick.ac.uk). The images are taken of a *C. elegans* one-cell embryo expressing a GFP fusion to the PH domain of Protein Lipase C delta 1 (PH-PLCd1). This domain binds PIP2, a lipid enriched in the plasma membrane. By using FRAP, we can investigate the dynamics of diffusion of the PH-PLCd1/PIP2 complex on the cell membrane, as well as the binding/unbinding dynamics of PH-PLCd1. The the FRAP experiment, a square patch of the membrane is exposed to intense light, thereby photobleaching the fluorescent molecules. If we quantify how the fluorescence returns to that region, we can infer the diffusion coefficient of the PH-PLCd1/PIP2 complex as well as the binding rate of the two molecules.\n",
    "\n",
    "We will be taking a simplified approach, but there is more sophisticated analysis we can do to get better estimates for the phenomenological coefficients. To motivate why you are processing the images, I will work through a physical model connecting the diffusion coefficient and binding constats to fluorescence recorvey.\n",
    "\n",
    "If $c$ is the concentration of the PH-PLDd1/PIP2 complex on the membrane and $c_\\mathrm{cyto}$ is the concentration of PH-PLCd1 in the cytoplasm (assumed to be spatially uniform since diffusion in the cytoplasm is very fast), the dynamics are described by a reaction-diffusion equation.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial c}{\\partial t} = D\\left(\\frac{\\partial^2 c}{\\partial x^2} + \\frac{\\partial^2 c}{\\partial y^2}\\right) + k_\\mathrm{on} c_\\mathrm{cyto} - k_\\mathrm{off} c.\n",
    "\\end{align}\n",
    "\n",
    "Here, $k_\\mathrm{on}$ and $k_\\mathrm{off}$ are the phenomenological rate constants for binding and unbinding to PIP2 on the membrane, and $D$ is the diffusion coefficient for the PH-PLCd1/PIP2 complex on the membrane.\n",
    "\n",
    "In [their paper](http://dx.doi.org/10.1016/j.bpj.2010.08.033), the authors discuss techniques for analyzing the data taking into account the fluorescence recovery of the bleached region in time and space. For simplicity here, we will only consider recovery of the normalized mean fluorescence. If $I(t)$ is the mean fluorescence of the bleached region and $I_0$ is the mean fluorescence of the bleached region immediately before photobleaching, we have, as derived in the paper,\n",
    "\n",
    "\\begin{align}\n",
    "I_\\mathrm{norm}(t) \\equiv \\frac{I(t)}{I_0} &= \n",
    "1 - f_b\\,\\frac{4 \\mathrm{e}^{-k_\\mathrm{off}t}}{d_x d_y}\\,\\psi_x(t)\\,\\psi_y(t),\\\\[1mm]\n",
    "\\text{where } \\psi_i(t) &= \\frac{d_i}{2}\\,\\mathrm{erf}\\left(\\frac{d_i}{\\sqrt{4Dt}}\\right)\n",
    "-\\sqrt{\\frac{D t}{\\pi}}\\left(1 - \\mathrm{e}^{-d_i^2/4Dt}\\right),\n",
    "\\end{align}\n",
    "\n",
    "where $d_x$ and $d_y$ are the extent of the photobleached box in the $x$- and $y$-directions, $f_b$ is the fraction of fluorophores that were bleached, and $\\mathrm{erf}(x)$ is the [error function](http://en.wikipedia.org/wiki/Error_function).  Note that this function is defined such that the photobleaching event occurs at time $t = 0$.\n",
    "\n",
    "We measure $I(t)$, $d_x$, and $d_y$. We can also measure $f_b$ as\n",
    "\n",
    "\\begin{align}\n",
    "f_b \\approx 1 - \\frac{I(0^+)}{I_0},\n",
    "\\end{align}\n",
    "\n",
    "though we will consider this a parameter to estimate.  In practice, the normalized fluorescent recovery does not go all the way to unity.  This is because the FRAP area is a significant portion of the membrane, and we have depleted fluorescent molecules.  We should thus adjust our equation to be\n",
    "\n",
    "\\begin{align}\n",
    "I_\\mathrm{norm}(t) \\equiv \\frac{I(t)}{I_0} &= \n",
    "f_f\\left(1 - f_b\\,\\frac{4 \\mathrm{e}^{-k_\\mathrm{off}t}}{d_x d_y}\\,\\psi_x(t)\\,\\psi_y(t)\\right),\n",
    "\\end{align}\n",
    "\n",
    "where $f_f$ is the fraction of fluorescent species left.  So, we have four parameters to use in regression, the physical parameters of interest, $D$ and $k_\\mathrm{off}$, and $f_f$ and $f_b$.\n",
    "\n",
    "The FRAP images come in a **TIFF stack**, which is a single TIFF file containing multiple frames.  You can load these with the `skimage.io.ImageCollection` class. Note that for this TIFF stack, the image collection is a list that contains a single image, which has all 149 frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this problem is to extract the mean normalized fluorescence versus time from each of the TIFF stacks for the experimental repeats.  Note that important information is contained in the associated README file.  You can download the data set [here](../data/goehring_FRAP_data.zip).\n",
    "\n",
    "The rest of the inference will be tackled in a subsequent homework. Be sure to store the results of your analysis in a CSV file so you can use it in future homework. (This is a good idea, anyway.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the tools of the trade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Image processing tools\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import bebi103\n",
    "\n",
    "import bokeh\n",
    "import bokeh.plotting\n",
    "import bokeh.io\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "from bokeh.models import Legend, LegendItem\n",
    "import itertools\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TIFF stack\n",
    "# The directory containing daytime data\n",
    "data_dir = '../data/goehring_FRAP_data'\n",
    "\n",
    "# Glob string for images\n",
    "im_glob = os.path.join(data_dir, '*.tif')\n",
    "\n",
    "# Get list of files in directory\n",
    "im_list = sorted(glob.glob(im_glob))\n",
    "\n",
    "\n",
    "image_collections = np.asarray(skimage.io.ImageCollection(im_list,\n",
    "                                          conserve_memory=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to take a look at the metadata for this dataset, because this will give hints as to how we should start to probe for the photobleaching region.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! textutil -convert txt '../data/goehring_FRAP_data/readme_PHdata.rtf' -output './4.1_readme.txt'\n",
    "! head -200 '4.1_readme.txt'\n",
    "! rm './4.1_readme.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the first photobleached frame is number 21. This will probably be the most valuable frame for determining the ROI. Let's load this image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = image_collections[0]\n",
    "print(\"Max: %i, Min: %i\" % (np.max(ic), np.min(ic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are 12-bit images, which max out at the value $2^{12} - 1 = 4095$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERPIXEL_DIST = 0.138 # in μm / pixel\n",
    "\n",
    "def display_im(image, title):\n",
    "    \"Displays a passed image.\"\n",
    "    plot = bebi103.viz.imshow(image,\n",
    "                              plot_height=300,\n",
    "                              title=title,\n",
    "                              interpixel_distance=INTERPIXEL_DIST,\n",
    "                              length_units='µm')\n",
    "    return plot\n",
    "plots = [display_im(ic[i], \"Frame %i\"%(i+1)) for i in range(19, 22)]\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! The metadata was correct, and it is absolutely clear that photobleaching occurs first in frame 21, and we can even see recovery begining in the 22nd frame. We know that the photobleached area is a 40x40 square, and we need to find the center in order to establish the ROI. I will do this by passing a mean filter over the image using a 40x40 structuring element, such that the darkest pixel in the filtered image actually represents the square containing the darkest 1600 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use a 40x40 square structuring element\n",
    "sq = skimage.morphology.square(40, dtype= np.uint16)\n",
    "\n",
    "# Perform the mean filter, using an offset so that the darkest pixel \n",
    "# is the top left corner of the ROI\n",
    "bleach_start_filt = skimage.filters.rank.mean(ic[20],\n",
    "                                              sq, \n",
    "                                              shift_x = -20, \n",
    "                                              shift_y = -20)\n",
    "# Display the result of the mean filter\n",
    "bokeh.io.show(display_im(bleach_start_filt, \"Mean filter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the minimum within this image! One problem with the way I set up this filter is that when it calculates the values for the bottom of the image, most of the values are zero (because they are out of the bounds of the image). We know *roughly* where the roi is, so I will just slice the bottom of the filtered image prior to finding the min. Slicing 39 pixels off the bottom can be done without the chance of missing the actual ROI in any of the images, since the ROI must be determined by a 40x40 pixel square in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off the bottom because of distorition due to filter. \n",
    "sliced = bleach_start_filt[:-39]\n",
    "# Display the sliced image to be sure I didn't cut out the ROI\n",
    "bokeh.io.show(display_im(sliced, \"Mean filter\"))\n",
    "# Get indices of the minimum-valued pixel\n",
    "ind = np.unravel_index(np.argmin(sliced, axis=None), sliced.shape)\n",
    "print(\"The top left region of the ROI is found at (%i, %i)\"%ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Let's see how our ROI:\n",
    "$$\n",
    "X \\rightarrow (12, 51)\\\\\n",
    "Y \\rightarrow (22, 61)\n",
    "$$\n",
    "matches up to the original photobleaching frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make grayscale image that is now RGB\n",
    "im = np.dstack(3*[ic[20]])\n",
    "\n",
    "# Pump up blue channel to highlight roi. \n",
    "im[12:52, 22:62, 2] = 1500\n",
    "\n",
    "# Create image with ROI highlighted\n",
    "p = bebi103.viz.imshow(im, \n",
    "                       color_mapper='rgb',\n",
    "                       interpixel_distance=INTERPIXEL_DIST,\n",
    "                       length_units='µm')\n",
    "\n",
    "# Create original image with the same color scheme\n",
    "gray_color_mapper = bebi103.viz.mpl_cmap_to_color_mapper('gray')\n",
    "plots = [p, bebi103.viz.imshow(ic[20], \n",
    "                               color_mapper = gray_color_mapper,\n",
    "                               interpixel_distance=INTERPIXEL_DIST,\n",
    "                               length_units='µm')]\n",
    "\n",
    "# Display both side-by-side\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ROI looks fantastic! I will now traverse through the entire image collection and collect summed raw intensity data from this ROI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_intensity = np.zeros(len(ic))\n",
    "for image, i in zip(ic, range(0, len(ic))):\n",
    "    raw_intensity[i] = np.sum(image[12:52, 22:62])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to normalize the intensity to be between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum intensity: %i\\nMinimum Intensity:  %i\"\n",
    "      %(np.max(raw_intensity), np.min(raw_intensity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the min and divide by the new max to normalize\n",
    "intensity = ((raw_intensity - np.min(raw_intensity)) / \n",
    "                    (np.max(raw_intensity) - np.min(raw_intensity)))\n",
    "\n",
    "# Time in seconds. Frames are spaced 0.188 seconds apart\n",
    "# according to the metadata (printed above)\n",
    "time = 0.188 * np.asarray(range(0, len(ic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot average normalized intensity over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bokeh.plotting.Figure(width = 600, \n",
    "                          height = 400,\n",
    "                          title = \"Normalized Fluorescence Intensity over Time\",\n",
    "                          x_axis_label = \"Time (seconds)\")\n",
    "p.circle(time, intensity)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I shall streamline this process for each image collection. I will start by making a more general function to determine ROIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi(ic):\n",
    "    \"\"\"Accepts an image collection and finds the pixels that correpsond to \n",
    "       the upper left corner of the ROI for the frap experiment of that\n",
    "       image collection.\"\"\"\n",
    "    # I will use a 40x40 square structuring element\n",
    "    sq = skimage.morphology.square(40, dtype= np.uint16)\n",
    "    \n",
    "    # Perform the mean filter, using an offset so that the darkest pixel \n",
    "    # is the top left corner of the ROI\n",
    "    bleach_start_filt = skimage.filters.rank.mean(ic[20], \n",
    "                                                  sq, \n",
    "                                                  shift_x = -20, \n",
    "                                                  shift_y = -20)\n",
    "    \n",
    "    # Cut off the bottom because of distorition due to filter. I had to \n",
    "    # include some additional bounds in order to correctly find all ROIs in\n",
    "    # the dataset. \n",
    "    sliced = bleach_start_filt[:-49][10:]\n",
    "    \n",
    "    # Get indices of the minimum-valued pixel\n",
    "    ind = np.asarray(np.unravel_index(np.argmin(sliced, axis=None), sliced.shape))\n",
    "    \n",
    "    # Correction for slicing\n",
    "    ind += np.array([10,0])\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will write a function to streamline the process of extracting and normalizing intensity data from each image collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intensity(ic, roi):\n",
    "    \"\"\"Computes the normalized intensities within the previously determined ROI\n",
    "    over the duration of the experiment.\"\"\"\n",
    "    # Extract raw intensity values, summed over the ROI\n",
    "    raw_intensity = np.zeros(len(ic))\n",
    "    for image, i in zip(ic, range(0, len(ic))):\n",
    "        raw_intensity[i] = np.sum(image[roi[0]:roi[0] + 40, roi[1]:roi[1] + 40])\n",
    "\n",
    "    # subtract the min and divide by the new max to normalize\n",
    "    intensity = ((raw_intensity - np.min(raw_intensity)) / \n",
    "                        (np.max(raw_intensity) - np.min(raw_intensity)))\n",
    "    return intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can cycle through the set of image collections and collect intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will store intensity arrays for each experiment. \n",
    "intensities = [0]*len(image_collections)\n",
    "\n",
    "# Time values are the same for each experiment.\n",
    "time = 0.188 * np.asarray(range(0, len(image_collections[0])))\n",
    "    \n",
    "for ic, index in zip(image_collections, range(0, len(image_collections))):\n",
    "    \n",
    "    # Obtain indicies of roi\n",
    "    roi = get_roi(ic)\n",
    "    \n",
    "    # Compute all total normalized fluoresnce intensities\n",
    "    intensity = get_intensity(ic, roi)\n",
    "    intensities[index] = intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will plot all intensities in a very similar way to the method I used for HW 3.2, because I love interactive legends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deals with coloring of different lines\n",
    "colors = itertools.cycle(palette)\n",
    "\n",
    "first = True # used to only show the first plot. \n",
    "\n",
    "p = bokeh.plotting.Figure(width = 800, \n",
    "                          height = 500,\n",
    "                          title = \"Normalized Fluorescence Intensity over Time\",\n",
    "                          x_axis_label = \"time (seconds)\")\n",
    "\n",
    "plots = [0] * len(image_collections)\n",
    "\n",
    "for index, color in zip(range(0,len(image_collections)), colors):\n",
    "    \n",
    "    # This is the experiment name (A-H)\n",
    "    name = im_list[index][-5:-4]\n",
    "    \n",
    "    q = p.line(time, \n",
    "               intensities[index], \n",
    "               line_width=2,\n",
    "               color = color,\n",
    "               visible = first, # used to only show the first plot. \n",
    "               line_join='bevel')\n",
    "    \n",
    "    # I must store the plots as legendItems so that I can make a cool legend. \n",
    "    plots[index] = LegendItem(label=name, renderers=[q])\n",
    "    \n",
    "    first = False # used to only show the first plot. \n",
    "\n",
    "# Make a super cool legend!!\n",
    "legend = Legend(items=plots,\n",
    "                location=(10,200),\n",
    "                click_policy = \"hide\")\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "p.add_layout(legend, 'right')\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks fabulous. The photobleaching clearly occurs at the same timepoint for each experiment, and slight discrepencies in recovery times can be easily discerned. For example, it appears that experiment E had a slower recovery than did experiment A, and experiments D and H experienced the least-complete full recovery. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "\n",
    "**Grade: 37/40**\n",
    "\n",
    "Good job overall!\n",
    "\n",
    "Note: You could have performed the filtering using your structuring element without passing it over those edge pixels that would give artificially low values by taking into account pixels outside the image frame.\n",
    "\n",
    "When calculating mean normalized intensity, as the equation in the problem statement shows, you only need to divide the raw intensity by $I_0$ such that the value immediately before photobleaching (or the maximum value, however you choose to define $I_0$) is 1.  Normalizing the intensity as per the mathematical model does not require making the minimum equal to 0, and this would affect subsequent analysis. (-2 pts)\n",
    "\n",
    "You were told to store the data as a csv. (-1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
