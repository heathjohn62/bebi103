{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Nice! 40/40\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "A) John\n",
    "\n",
    "B and C) Jared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7.2: MCMC with Boolean data (40 pts)\n",
    "\n",
    "In [Homework 6](hw6.html), you investigated a data set on reversals of optogenetic worms upon exposure to blue light. As a reminder, here are the data.\n",
    "\n",
    "|Strain|Year|Trials|Reversals|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|WT|2017|55|7|\n",
    "|ASH|2017|54|18|\n",
    "|AVA|2017|52|28|\n",
    "|WT|2016|36|6|\n",
    "|ASH|2016|35|12|\n",
    "|AVA|2016|36|30|\n",
    "|WT|2015|35|0|\n",
    "|ASH|2015|35|9|\n",
    "|AVA|2015|36|33|\n",
    "\n",
    "Again, for the purposes of this problem, assume that we can pool the results from the two years to have 13/126 reversals for wild type, 39/124 reversals for ASH, and 91/124 reversals for AVA.\n",
    "\n",
    "The pertinent parameter is $\\theta$, the probability of reversal of a worm upon illumination.\n",
    "\n",
    "**a)** Use Stan to get samples of $\\theta$ for each of the three strains. Plot either histograms or ECDFs of your samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import bebi103\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "bokeh.io.output_notebook()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "import scipy.stats as st\n",
    "# Import Altair for high level plotting\n",
    "import altair as alt\n",
    "import altair_catplot as altcat\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior predictive check\n",
    "I wrote the stan prior-predictive model, and I'll show it here. Again, we are modeling the number of reversals as a binomial distribution, such that the probability of reversal has a beta-distributed prior. The parameters of the beta distribution are different for each strain of worm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = bebi103.stan.StanModel(file='./7.2_prior_pred.stan')\n",
    "print(sm.model_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will pass this generative model the parameters of the experiment and generate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays for alpha and beta values for our three strains\n",
    "a_array = [1, 2, 5]\n",
    "b_array = [8, 7, 6]\n",
    "\n",
    "# arrays for the datapoints we have for number of reversals for our three strains\n",
    "n_array = [13, 39, 91]\n",
    "N_array = [126, 124, 124]\n",
    "\n",
    "# Store input parameters in a dictionary so stan can access them\n",
    "data = dict(N=3,\n",
    "            alpha = a_array,\n",
    "            beta_ = b_array,\n",
    "            trials = N_array)\n",
    "\n",
    "# Generate samples\n",
    "samples_gen = sm.sampling(data=data,\n",
    "                          algorithm='Fixed_param',\n",
    "                          warmup=0,\n",
    "                          chains=1,\n",
    "                          iter=1000)\n",
    "# Store samples in a dataframe\n",
    "df_gen = bebi103.stan.to_dataframe(samples_gen, diagnostics=False)\n",
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the sampling worked well. Let's plot the distribution for each theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ecdf(n, name, color, p):\n",
    "    return bebi103.viz.ecdf(n, \n",
    "                            color = color,\n",
    "                            legend= name,\n",
    "                            alpha=1, \n",
    "                            line_alpha=0,\n",
    "                            p=p)\n",
    "p = bokeh.plotting.Figure(x_axis_label='probability of reversal')\n",
    "p = show_ecdf(df_gen[\"theta[1]\"].values, \"WT\", \"blue\", p)\n",
    "p = show_ecdf(df_gen[\"theta[2]\"].values, \"ASH\", \"red\", p)\n",
    "p = show_ecdf(df_gen[\"theta[3]\"].values, \"AVA\", \"black\", p)\n",
    "p.legend.location = \"bottom_right\" \n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prior-predictive check makes perfect sense. We expect most wildtype reversal probabilities to be very low, and ASH and AVA probabilities to each be higher than one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAN MCMC\n",
    "I will now write models to perform sampling from the posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_mcmc_wt = bebi103.stan.StanModel(file='./7.2_mcmc_wt.stan')\n",
    "sm_mcmc_ash = bebi103.stan.StanModel(file='./7.2_mcmc_ash.stan')\n",
    "sm_mcmc_ava = bebi103.stan.StanModel(file='./7.2_mcmc_ava.stan')\n",
    "print(\"-------------WT MODEL-------------\")\n",
    "print(sm_mcmc_wt.model_code)\n",
    "print(\"-------------ASH MODEL-------------\")\n",
    "print(sm_mcmc_ash.model_code)\n",
    "print(\"-------------AVA MODEL-------------\")\n",
    "print(sm_mcmc_ava.model_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by sampling from the posterior for the wildtype species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wt =  dict(N = 3,\n",
    "                WT = 13,\n",
    "                trials = N_array[0])\n",
    "data_ash = dict(N = 3,\n",
    "                ASH = 39, \n",
    "                trials = N_array[1])\n",
    "data_ava = dict(N = 3, \n",
    "                AVA = 91,\n",
    "                trials = N_array[2])\n",
    "samples_wt = sm_mcmc_wt.sampling(data=data_wt)\n",
    "df_mcmc_wt = bebi103.stan.to_dataframe(samples_wt, diagnostics=False)\n",
    "df_mcmc_wt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to repeat sampling for the other two strains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ash = sm_mcmc_ash.sampling(data=data_ash)\n",
    "df_mcmc_ash = bebi103.stan.to_dataframe(samples_ash, diagnostics=False)\n",
    "df_mcmc_ash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ava = sm_mcmc_ava.sampling(data=data_ava)\n",
    "df_mcmc_ava = bebi103.stan.to_dataframe(samples_ava, diagnostics=False)\n",
    "df_mcmc_ava.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can plot my samples from the posterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bokeh.plotting.Figure(x_axis_label='probability of reversal')\n",
    "p = show_ecdf(df_mcmc_wt[\"theta\"].values, \"WT\", \"blue\", p)\n",
    "p = show_ecdf(df_mcmc_ash[\"theta\"].values, \"ASH\", \"red\", p)\n",
    "p = show_ecdf(df_mcmc_ava[\"theta\"].values, \"AVA\", \"black\", p)\n",
    "p.legend.location = \"bottom_right\" \n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use your Metropolis-Hastings sampler from the previous problem to do the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm going to include all the functions we made in the previous problem. We explained this code previously, so I'm not going to explain it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_step(x, logpost, logpost_current, sigma, args=()):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_variables,)\n",
    "        The present location of the walker in parameter space.\n",
    "    logpost : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `logpost(x, *args)`.\n",
    "    logpost_current : float\n",
    "        The current value of the log posterior.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `logpost()` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray, shape (n_variables,)\n",
    "        The position of the walker after the Metropolis-Hastings\n",
    "        step. If no step is taken, returns the inputted `x`.\n",
    "    \"\"\"\n",
    "    # Turn sigma into a diagonal matrix so that it can be used as\n",
    "    # the covariance matrix for numpy's multivariate guassian function\n",
    "    cov = np.diag(sigma * sigma) # squared because variance is std. squared\n",
    "    \n",
    "    # Now I will choose the next step, x-prime\n",
    "    xp = np.random.multivariate_normal(x, cov, 1)[0]\n",
    "    \n",
    "    # Compute the log-posterior at x-prime\n",
    "    logpost_xp = logpost(xp, *args)\n",
    "    \n",
    "    # Calculate metropolis ratio\n",
    "    r = np.exp(logpost_xp - logpost_current)\n",
    "    \n",
    "    if (r >= 1):\n",
    "        return xp\n",
    "    elif(np.random.rand() < r):\n",
    "        return xp\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acceptance_rate(output_df):\n",
    "    \"\"\"Determines the acceptance rate of an MCMC sampler within the passed\n",
    "    dataframe containing MCMC samples. \"\"\"\n",
    "    num_rejections = 0\n",
    "    last_row = np.zeros(len(output_df.loc[0].values))\n",
    "    for row in output_df.iterrows():\n",
    "        row = row[1].values\n",
    "        if (row == last_row).all():\n",
    "            num_rejections += 1\n",
    "        last_row = row\n",
    "    return (len(output_df.index) - num_rejections) / len(output_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_std_dev_correction(acceptance_rate):\n",
    "    \"\"\"Returns the necessary multiplicative correction to the standard deviation\n",
    "    of the proposal distribution given an acceptance rate for the metropolis-\n",
    "    hastings MCMC sampler. \"\"\"\n",
    "    if acceptance_rate < .001:\n",
    "        return 0.1\n",
    "    elif acceptance_rate < 0.05:\n",
    "        return 0.5\n",
    "    elif acceptance_rate < 0.2:\n",
    "        return 0.9\n",
    "    elif acceptance_rate < 0.5:\n",
    "        return 1\n",
    "    elif acceptance_rate < 0.75:\n",
    "        return 1.1\n",
    "    elif acceptance_rate < 0.95:\n",
    "        return 2\n",
    "    else:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_sample_optimize_acceptance(logpost, \n",
    "                                  x0, \n",
    "                                  sigma, \n",
    "                                  args=(), \n",
    "                                  n_burn=1000, \n",
    "                                  n_steps=1000, \n",
    "                                  n_opt_acc = 1000,\n",
    "                                  variable_names=None):\n",
    "    \"\"\"New sampling function that includes optimization of sigma\n",
    "    with respect to the acceptance rate. n_opt_acc indicates the number\n",
    "    of steps that should be used to optimize, but all other parameters\n",
    "    are identical to those used in mh_sample()\"\"\"\n",
    "    \n",
    "    # Define variable names\n",
    "    if variable_names == None:\n",
    "        variable_names = list(range(len(x0)))\n",
    "    \n",
    "    # Define starting points\n",
    "    x = x0\n",
    "    logpost_current = logpost(x, *args)\n",
    "        \n",
    "    # Burn step    \n",
    "    for c in range(n_burn):\n",
    "        x = mh_step(x, logpost, logpost_current, sigma, args=args)\n",
    "        logpost_current = logpost(x, *args)\n",
    "    \n",
    "    # Starting optimization!!\n",
    "    iterations = 0\n",
    "    while(True):\n",
    "        # Make arrays to take optimization data\n",
    "        samples_opt = [0]*n_opt_acc\n",
    "        logpost_values_opt = np.empty([len(range(n_opt_acc))])\n",
    "\n",
    "        # Do the sampling\n",
    "        for k in range(n_opt_acc):\n",
    "            x = mh_step(x, logpost, logpost_current, sigma, args=args)\n",
    "            logpost_current = logpost(x, *args)\n",
    "            samples_opt[k] = x\n",
    "            logpost_values_opt[k] = logpost_current\n",
    "\n",
    "        # Convert arrays to dataframe    \n",
    "        df_opt =  pd.DataFrame(data=samples_opt, columns = variable_names)\n",
    "        df_opt[\"lnprob\"] = logpost_values_opt\n",
    "        \n",
    "        # Calculate acceptance rate and optimize sigma\n",
    "        rate = calc_acceptance_rate(df_opt)\n",
    "        opt_factor = find_std_dev_correction(rate)\n",
    "        sigma *= opt_factor\n",
    "        \n",
    "        # If the acceptance rate was way off, repeat this process again. \n",
    "        # Otherwise, we can exit the loop\n",
    "        if (opt_factor == 1):\n",
    "            break\n",
    "            \n",
    "        # This program has the potential for an infinite loop. I don't want\n",
    "        # this to happen, so if this iterates 10 times I'll print a warning\n",
    "        # statement and stop optimizing. \n",
    "        iterations += 1\n",
    "        if iterations >= 10:\n",
    "            print(\"WARNING: Acceptance rate did not converge!\")\n",
    "            break\n",
    "    \n",
    "    # Make arrays to take data\n",
    "    samples = [0]*n_steps\n",
    "    logpost_values = np.empty([len(range(n_steps))])\n",
    "    \n",
    "    # Do the sampling\n",
    "    for k in range(n_steps):\n",
    "        x = mh_step(x, logpost, logpost_current, sigma, args=args)\n",
    "        logpost_current = logpost(x, *args)\n",
    "        samples[k] = x\n",
    "        logpost_values[k] = logpost_current\n",
    "        \n",
    "    \n",
    "    # Convert arrays to dataframe    \n",
    "    df =  pd.DataFrame(data=samples, columns = variable_names)\n",
    "    df[\"lnprob\"] = logpost_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to input our data and models into arrays, which we did last week for this same problem. Using the same model we used last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays for alpha and beta values for our three strains\n",
    "a_array = [1, 2, 5]\n",
    "b_array = [8, 7, 6]\n",
    "\n",
    "# arrays for the datapoints we have for number of reversals for our three strains\n",
    "n_array = [13, 39, 91]\n",
    "N_array = [126, 124, 124]\n",
    "# array for the names of the conditions\n",
    "name_array = ['WT', 'ASH', 'AVA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define a log post function that fits our model as we defined it last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_post_reversal(x, a, b, n, N):\n",
    "    # Priors are beta distributions, different for each condition\n",
    "    log_prior = st.beta.logpdf(x, a, b)\n",
    "\n",
    "    # The log_likelihood is just the binomial distribution\n",
    "    log_like = np.sum(st.binom.logpmf(n, N, x))\n",
    "\n",
    "    return log_prior + log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run the sampler for each of the three conditions and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess for MCMC\n",
    "x_0 =np.array([1])\n",
    "# Standard Deviations for proposal dist.\n",
    "s = np.array([1.])\n",
    "\n",
    "# Sample the three conditions\n",
    "for i in range(3):\n",
    "    df_mcmc_temp = mh_sample_optimize_acceptance(log_post_reversal, \n",
    "                         x_0, \n",
    "                         s, \n",
    "                         args = (a_array[i], b_array[i], n_array[i], N_array[i]),\n",
    "                         n_steps=5000,\n",
    "                         variable_names = [\"theta\"])\n",
    "    df_mcmc_temp[\"Condition\"] = name_array[i]\n",
    "    if i == 0:\n",
    "        df_mcmc_total = df_mcmc_temp\n",
    "    else:\n",
    "        df_mcmc_total = pd.concat([df_mcmc_total, df_mcmc_temp])\n",
    "\n",
    "# Plot\n",
    "altcat.catplot(data=df_mcmc_total,\n",
    "               mark='line',\n",
    "               encoding=dict(x=alt.X('theta:Q',\n",
    "                                     scale=alt.Scale(\n",
    "                                     domain=(0, 1),\n",
    "                                     clamp=True)),\n",
    "                            color = alt.Color('Condition:N', title='System')),\n",
    "               transform='ecdf'\n",
    "              ).properties(height=300,\n",
    "                           width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks just like how we'd expect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**c)** The posterior plots of $\\theta$ are illuminating, but suppose we want to quantify *the difference* in reversal probability between the two strains, say strain 1 and strain 2. That is, we want to compute $g(\\delta_{12}\\mid n_1, N_1, n_2, N_2)$, where $\\delta_{12} \\equiv \\theta_2 - \\theta_1$. Note that computing this distribution by hand is quite difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify this difference we can simply take the difference between the two distributions. To do this I will first get samples for theta for each of the three conditions in one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess for MCMC\n",
    "x_0 =np.array([1])\n",
    "# Standard Deviations for proposal dist.\n",
    "s = np.array([1.])\n",
    "\n",
    "for i in range(3):\n",
    "    df_mcmc_temp = mh_sample_optimize_acceptance(log_post_reversal, \n",
    "                         x_0, \n",
    "                         s, \n",
    "                         args = (a_array[i], b_array[i], n_array[i], N_array[i]),\n",
    "                         n_steps=5000,\n",
    "                         variable_names = [name_array[i]])\n",
    "    if i == 0:\n",
    "        df_mcmc_total2 = df_mcmc_temp\n",
    "    else:\n",
    "        df_mcmc_total2[name_array[i]] = df_mcmc_temp[name_array[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use dataframe methods to compute the difference between the thetas each two of the three strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc_total2[\"ASH-WT\"]= df_mcmc_total2[\"ASH\"] - df_mcmc_total2[\"WT\"]\n",
    "df_mcmc_total2[\"AVA-WT\"]= df_mcmc_total2[\"AVA\"] - df_mcmc_total2[\"WT\"]\n",
    "df_mcmc_total2[\"AVA-ASH\"]= df_mcmc_total2[\"AVA\"] - df_mcmc_total2[\"ASH\"]\n",
    "df_mcmc_total2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this easier to plot I will now tidy the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc_total2 = df_mcmc_total2.drop(['lnprob', 'WT','ASH','AVA'], axis = 1)\n",
    "df_mcmc_total2_tidy = df_mcmc_total2.stack(level=0)\n",
    "df_mcmc_total2_tidy = df_mcmc_total2_tidy.sort_index(level=1)\n",
    "df_mcmc_total2_tidy = df_mcmc_total2_tidy.reset_index(level=1)\n",
    "df_mcmc_total2_tidy = df_mcmc_total2_tidy.rename(columns={'level_1': 'Condition', \n",
    "                                                          0:'delta'})\n",
    "df_mcmc_total2_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altcat.catplot(data=df_mcmc_total2_tidy,\n",
    "               mark='line',\n",
    "               encoding=dict(x=alt.X('delta:Q',\n",
    "                                     scale=alt.Scale(\n",
    "                                     domain=(0, 1),\n",
    "                                     clamp=True)),\n",
    "                            color = alt.Color('Condition:N', title='System')),\n",
    "               transform='ecdf'\n",
    "              ).properties(height=300,\n",
    "                           width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, this looks great! Unsurprisingly, the difference is smallest between the two lowest probability strains, and highest between the lowest and highest probability strains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
