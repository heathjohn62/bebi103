{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "A) John\n",
    "\n",
    "B) and C) Jared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6.2: Least squares (20 pts)\n",
    "\n",
    "You may have heard that to estimate the best-fit parameters for a regression, you should \"minimize the sum of the squares of the residuals.\" In this problem, we will parse what that means and understand it in the context of generative Bayesian modeling.\n",
    "\n",
    "Say I have some (x, y) data, where x is the independent variable (known essentially exactly; this could be something like time) and y is the dependent variable (which has some stochasticity of noise in its measurement). Imagine that we have derived a theoretical relation between our expected y and x, and that relation is written as $y = f_y(x;\\theta)$, there $\\theta$ is some set of parameters that we wish to determine from our regression.\n",
    "\n",
    "Our data set is $\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\}$. We assume the measurements of $y$ are i.i.d. and Gaussian distributed.\n",
    "\n",
    "\\begin{align}\n",
    "y_i \\sim \\mathrm{Norm}(f_y(x_i;\\theta), \\sigma_i) \\;\\;\\forall i.\n",
    "\\end{align}\n",
    "\n",
    "A **residual** for a data point is defined as\n",
    "\n",
    "\\begin{align}\n",
    "r_i = \\frac{y_i - f_y(x_i;\\theta)}{\\sigma_i}.\n",
    "\\end{align}\n",
    "\n",
    "The sum of the squares of the residuals is then\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^N r_i^2 = \\sum_{i=1}^N\\,\\frac{(y_i - f_y(x_i;\\theta))^2}{\\sigma_i^2}.\n",
    "\\end{align}\n",
    "\n",
    "**a)** Show that finding the parameters $\\theta$ that minimize the sum of the squares of the residuals is equivalent to finding the MAP parameters for a model with the above likelihood and Uniform priors on all parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all priors are uniform, the probability of a given outcome $y$ with dependent variable $x_i$ is given by the normal distribution with a mean centered about $f_y(x_i;\\theta_i)$ with standard deviation $\\sigma_i$. This is expressed as the following:\n",
    "$$\n",
    "\\mathbb{P}(y |\\theta_i, x_i) = \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp{(-\\frac{(y- f_y(x_i; \\theta))^2}{2 \\sigma_i^2})}\n",
    "$$\n",
    "Thus, the probability of obtaining every point $y_i$ in our dataset is given by the product:\n",
    "$$\n",
    "\\mathbb{P}(y_1, y_2, ..., y_N | x_1, x_2, ..., x_N, \\theta)= \\prod_{i=1}^N{\\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp{(-\\frac{(y_i- f_y(x_i; \\theta))^2}{2 \\sigma_i^2})}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, I will substitute:\n",
    "$$\\mathbb{P}(\\mathcal{D}|\\theta) = \\mathbb{P}(y_1, y_2, ..., y_N | x_1, x_2, ..., x_N, \\theta)$$\n",
    "where $\\mathbb{P}(\\mathcal{D}|\\theta)$ is the probability of obtaining the dataset given parameters $\\theta$. \n",
    "\n",
    "MAP parameters necessarily maximize the above product, so we want to consider the case where the product is maximized with respect to theta. Since maximizing $\\log{\\mathbb{P}}$ is the same as maximizing $\\mathbb{P}$, we can take the logarithm of both sides without changing the $\\theta$ that maximizes both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log{(\\mathbb{P}(\\mathcal{D}|\\theta))} = \\prod_{i=1}^N{(\\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}})} * \\sum_{j=1}^N{(-\\frac{(y_j- f_y(x_j; \\theta))^2}{2 \\sigma_j^2})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now note that maximizing the probability is the same as minimizing the negative log probability. Thus, we now desire the parameters $\\theta$ such that the product:\n",
    "$$\n",
    "-\\log{(\\mathbb{P}(\\mathcal{D}|\\theta))} = \\prod_{i=1}^N{(\\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}})} * \\sum_{j=1}^N{(\\frac{(y_j- f_y(x_j; \\theta))^2}{2 \\sigma_j^2})}\n",
    "$$\n",
    "is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma_i$ has no theta dependence, as it is simply drawn from a uniform distribution. Since we are not maximizing with respect to $\\sigma_i$, for **any** nonzero and real $\\sigma_i$, the product $\\prod_{i=1}^N{(\\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}})}$ is simply a positive constant, and will only scale $-\\log{(\\mathbb{P}(\\mathcal{D}|\\theta))}$ without changing extrema. Thus, we can eliminate this term from the equation without changing the $\\theta$ that yeilds the minimum negative log probability that we seek. \n",
    "\n",
    "Thus, the MAP parameter $\\theta$ must minimize the sum:\n",
    "$$\\frac{-2\\log{(\\mathbb{P}(\\mathcal{D}|\\theta))}}{\\prod_{i=1}^N{(\\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}})}} = \\sum_{j=1}^N{(\\frac{(y_j- f_y(x_j; \\theta))^2}{\\sigma_j^2})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly minimizing the sum of the square of the residuals, so we are done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#D9EDF7\">\n",
    "Right! 10/10\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Show further that if we assume **homoscedastic** errors, that is that $\\sigma_i = \\sigma$ for all $i$, then we do not need to consider the parameter $\\sigma$ at all in finding the MAP values for $\\theta$. This is often the procedure that is done with least squares regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From part A we know that to find the MAP values for $\\theta$ we must minimize the sum of the squares of the residuals, so we must minimize:\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^N r_i^2 = \\sum_{i=1}^N\\,\\frac{(y_i - f_y(x_i;\\theta))^2}{\\sigma_i^2}.\n",
    "\\end{align}\n",
    "\n",
    "However, if $\\sigma_i = \\sigma$ for all $i$, then\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^N r_i^2 = \\sum_{i=1}^N\\,\\frac{(y_i - f_y(x_i;\\theta))^2}{\\sigma_i^2}= \\sum_{i=1}^N\\,\\frac{(y_i - f_y(x_i;\\theta))^2}{\\sigma^2}=\\frac{\\sum_{i=1}^N\\,{(y_i - f_y(x_i;\\theta))^2}}{\\sigma^2}.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, because the value of $\\sigma$ is constant, to minimize the sum of the squares we really only need to minimize the numerator, so to find the MAP values for $\\theta$ we can ignore the parameter $\\sigma$ and find the values of $\\theta$ that minimize:\n",
    "\\begin{align}\n",
    "{\\sum_{i=1}^N\\,{(y_i - f_y(x_i;\\theta))^2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we don't need to consider $\\sigma$ at all, as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#D9EDF7\">\n",
    "Correct! 5/5\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Discuss any issues you see with taking this approach. Think generatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious issue with this approach is that the assumption of homoscedastic errors is not necessarily valid. For example, it is possible, and in some cases likely, that noise and errors may increase over time, which invalidates our assumption. If the variance changes in response to some variable, our assumption is invalid. Thus, we must be careful when we are using this assumption to make sure it actually reflects the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#D9EDF7\">\n",
    "Good point! 5/5. Another thing to think about is the case where we take a uniform prior without bounds (which we are allowed to do, though it is improper since it does not sum to one). In that case, we no longer even have a generative model since we cannot draw random parameter choices out of an unbounded distribution (as Justin has mentioned, all draws would be infinite). That means that the assumptions of uniform, improper priors make it so we no longer have a generative model, and we won't be able to do prior predictive checks.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
