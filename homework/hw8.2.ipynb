{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "**a)** All Jared\n",
    "\n",
    "**b)** Mostly Maria, everyone brainstormed priors in class.\n",
    "\n",
    "**c)** All Maria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import arviz as az\n",
    "\n",
    "import bebi103\n",
    "\n",
    "# Import Altair for high level plotting\n",
    "import altair as alt\n",
    "import altair_catplot as altcat\n",
    "# Pevent bulky altair plots\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.2: Microtubule catastrophe, 40 pts\n",
    "\n",
    "_Note: This problem is best done after the lecture November 22._\n",
    "\n",
    "In this problem, we use data from [Gardner, Zanic, et al., Depolymerizing kinesins Kip3 and MCAK shape cellular microtubule architecture by differential control of catastrophe, *Cell*, **147**, 1092-1103, 2011](https://doi.org/10.1016/j.cell.2011.10.037). The authors investigated the dynamics of microtubule catastrophe, the switching of a microtubule from a growing to a shrinking state.  In particular, they were interested in the time between the start of growth of a microtubule and the catastrophe event. They monitored microtubules in a single-molecule [TIRF assay](https://en.wikipedia.org/wiki/Total_internal_reflection_fluorescence_microscope) by using tubulin (the monomer that comprises a microtubule) that was labeled with a fluorescent marker. As a control to make sure that fluorescent labels and exposure to laser light did not affect the microtubule dynamics, they performed a similar experiment using differential interference contrast (DIC) microscopy. They measured the time until catastrophe with labeled and unlabeled tubulin. We will carefully analyze the data and make some conclusions about the processes underlying microtubule catastrophe.\n",
    "\n",
    "In the file `gardner_mt_catastrophe_only_tubulin.csv` (which you can download [here](../data/gardner_mt_catastrophe_only_tubulin.csv)), we have observed catastrophe times of microtubules with different concentrations of tubulin. To start with, we will consider the experiment run with a tubulin concentration of 12 ÂµM. So, our data set consists of a set of measurements of the amount of time to catastrophe. We will consider three models for microtubule catastrophe.\n",
    "\n",
    "- Model 1: The time to catastrophe is Exponentially distributed.\n",
    "- Model 2: The time to catastrophe is Gamma distributed.\n",
    "- Model 3: The time to catastrophe is Weibull distributed.\n",
    "\n",
    "Note that these descriptions are for the likelihood; we have not specified priors.\n",
    "\n",
    "\n",
    "**a)  Describe the three models in words. Give physical descriptions of the meanings of their parameters. Describe how these models are related to each other. Tutorial 3c will be useful.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1: The time to catastrophe is Exponentially distributed.\n",
    "\n",
    "This suggests that the occurance of catastrophe is a Poisson process, so it is a \"rare event\" that requires multiple subprocesses to lead it it. The parameter for the process, if it is exponential, $\\beta$, represents the characteristic rate of catastrophe, that is how often catastrophe happens in a certain amount of time. It can also be parametrized as $\\tau=1/\\beta$, the characteristic catastrophe time, which fits what we are given in our data. The Exponential distribution is a special case of the Gamma distribution where $\\alpha = 1$ and a special case of the Weibull distribution where $\\alpha = 1$ and $\\sigma=1/\\beta$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 2: The time to catastrophe is Gamma distributed.\n",
    "\n",
    "This suggests that the occurance of catastrophe represents a specific number of occurances of a Poisson process, that is a discrete number of steps that occur at the same rate must occur for catastrophe to occur. There are two parameters for this distribution, $\\alpha$ and $\\beta$, where $\\alpha$ is the number of arrivals (or \"steps\") required to trigger catastrophe, and $\\beta$ is the rate of the arrivals. Thus, the characteristic catastrophe time is given by $\\alpha/\\beta$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 3: The time to catastrophe is Weibull distributed.\n",
    "\n",
    "This suggests that the likelihood of catastrophe is dependent on the amount of time it has been since the last catastrophe, so the longer it has been since the last catastrophe, the more likely it is that catastrophe will occur. There are two parameters for this distribution, $\\alpha$ which defines how the probability changes over time, and $\\sigma$ which is the characteristic catastrophe time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Perform parameter estimates for the respective models and make model comparisons. Comment on what this means with respect to our understanding of how microtubule catastrophe works.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in our data and come up with our priors for the parameters of the three distributions. We don't have much prior knowledge so we will keep them simple (normal distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential(beta)**\n",
    "\n",
    "tau ~ normal(400, 100)\n",
    "\n",
    "beta = 1/tau\n",
    "\n",
    "We guess that the castastrophe times will be in the hundreds.\n",
    "\n",
    "**Gamma($\\alpha$, $\\beta$)**\n",
    "\n",
    "alpha ~ normal(10, 3)\n",
    "\n",
    "We assume that it will take around 10 arrivals to trigger catastrophe.\n",
    "\n",
    "tau ~ normal(150, 50)\n",
    "\n",
    "beta = 1/tau\n",
    "\n",
    "\n",
    "**Weibull($\\alpha$, $\\sigma$)**\n",
    "\n",
    "$\\alpha$ ~ normal(1, 0.1)\n",
    "\n",
    "We think that the rate of catastrophe is not dependent on the time elapsed from the last event, so we center our distribution aroud 1 without much variation.\n",
    "\n",
    "$\\sigma$ ~ normal(10, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gardner_mt_catastrophe_only_tubulin.csv', comment = \"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 uM</th>\n",
       "      <th>7 uM</th>\n",
       "      <th>9 uM</th>\n",
       "      <th>10 uM</th>\n",
       "      <th>14 uM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.429</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    12 uM  7 uM  9 uM  10 uM  14 uM\n",
       "0  25.000  35.0  25.0   50.0   60.0\n",
       "1  40.000  45.0  40.0   60.0   75.0\n",
       "2  40.000  50.0  40.0   60.0   75.0\n",
       "3  45.429  50.0  45.0   75.0   85.0\n",
       "4  50.000  55.0  50.0   75.0  115.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the data we are working with\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c0903ec82a19de1bfb9fb132714a9c40 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaredlivingston/anaconda3/lib/python3.6/site-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /var/folders/w3/tn6brvj12bx95d_v766ht54h0000gn/T/tmpgv_ymvzi/stanfit4anon_model_c0903ec82a19de1bfb9fb132714a9c40_3422403499193077404.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_43e7521b063a968e193cf3a1be7574a6 NOW.\n",
      "/Users/jaredlivingston/anaconda3/lib/python3.6/site-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /var/folders/w3/tn6brvj12bx95d_v766ht54h0000gn/T/tmp3vt1b5pr/stanfit4anon_model_43e7521b063a968e193cf3a1be7574a6_8102683413684293024.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    }
   ],
   "source": [
    "prior_sm1 = bebi103.stan.StanModel(file='./8.2_prior_pred_12_m1.stan')\n",
    "prior_sm2 = bebi103.stan.StanModel(file='./8.2_prior_pred_12_m2.stan')\n",
    "prior_sm3 = bebi103.stan.StanModel(file='./8.2_prior_pred_12_m3.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store input parameters in a dictionary so stan can access them\n",
    "data = dict(N=692)\n",
    "\n",
    "# Generate samples\n",
    "samples_gen1 = prior_sm1.sampling(data=data,\n",
    "                          algorithm='Fixed_param',\n",
    "                          warmup=0,\n",
    "                          chains=1,\n",
    "                          iter=1000)\n",
    "samples_gen2 = prior_sm2.sampling(data=data,\n",
    "                          algorithm='Fixed_param',\n",
    "                          warmup=0,\n",
    "                          chains=1,\n",
    "                          iter=1000)\n",
    "samples_gen3 = prior_sm3.sampling(data=data,\n",
    "                          algorithm='Fixed_param',\n",
    "                          warmup=0,\n",
    "                          chains=1,\n",
    "                          iter=1000)\n",
    "\n",
    "# Store samples in a dataframe\n",
    "df_gen1 = bebi103.stan.to_dataframe(samples_gen1, diagnostics=False)\n",
    "df_gen2 = bebi103.stan.to_dataframe(samples_gen2, diagnostics=False)\n",
    "df_gen3 = bebi103.stan.to_dataframe(samples_gen3, diagnostics=False)\n",
    "\n",
    "# Let's look at one of the dataframes to make sure they look ok\n",
    "df_gen3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! It looks ok so we can move on to plotting our prior predictive checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bebi103.viz.predictive_ecdf(samples_gen1, \"time\",\n",
    "                                x_axis_label = \"intercatastrophe time (s)\")\n",
    "p.x_range = bokeh.models.Range1d(-10, 6000)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bebi103.viz.predictive_ecdf(samples_gen2, \"time\",\n",
    "                                x_axis_label = \"intercatastrophe time (s)\")\n",
    "p.x_range = bokeh.models.Range1d(-10, 3000)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bebi103.viz.predictive_ecdf(samples_gen3, \"time\",\n",
    "                                x_axis_label = \"intercatastrophe time (s)\")\n",
    "p.x_range = bokeh.models.Range1d(-10, 1000)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our priors look reasonable, since times are centered in the hundreds, so now we can move on to creating our mcmc models and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm1 = bebi103.stan.StanModel(file='./8.2_mcmc_12_m1.stan')\n",
    "sm2 = bebi103.stan.StanModel(file='./8.2_mcmc_12_m2.stan')\n",
    "sm3 = bebi103.stan.StanModel(file='./8.2_mcmc_12_m3.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N=len(df),\n",
    "           time=df['12 uM'].values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = sm1.sampling(data=data)\n",
    "samples2 = sm2.sampling(data=data)\n",
    "samples3 = sm3.sampling(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc1 = bebi103.stan.to_dataframe(samples1, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc2 = bebi103.stan.to_dataframe(samples2, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc3 = bebi103.stan.to_dataframe(samples3, diagnostics=False, inc_warmup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the post predictive checks to do model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples1, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['12 uM'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is a systematic issue with using the exponential distribution becuase the two inflection points will always be in the wrong place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples2, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['12 uM'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gamma distribution looks a lot more promising! Most of our values fall into that innermost confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples3, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['12 uM'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooof the weibull distribution model is also not great (better than exponential though). Only a few of our datapoints will fall in that 99% confidence interval, so the curve isn't a very good match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm quantitatively, we compute the loo given the log likelihood and use the bebi103 compare function to calculate the loo and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'exponential': samples1, 'gamma': samples2, 'weibull': samples3},\n",
    "                     log_likelihood='log_like', ic='loo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that gamma (Model 2) is the best distribution to fit our data because the weight is much higher (0.95 vs 10^-2 and 10^-13). Based on the visual analysis of the post predictive checks above,  this makes a lot of sense! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Using whichever model you favor based on your work in part (b), obtain parameter estimates for the other tubulin concentrations. Given that microtubules polymerize faster with higher tubulin concentrations, is there anything you can say about the occurrence of catastrophe by looking at the values of the parameters versus tubulin concentration?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We picked the gamma distribution model so we will now sample out of it for all 5 concentrations in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data12 = dict(N=len(df),\n",
    "           time=df['12 uM'].values.astype(float))\n",
    "data7 = dict(N=len(df['7 uM'].dropna()),\n",
    "           time=df['7 uM'].dropna().values.astype(float))\n",
    "data9 = dict(N=len(df['9 uM'].dropna()),\n",
    "           time=df['9 uM'].dropna().values.astype(float))\n",
    "data10 = dict(N=len(df['10 uM'].dropna()),\n",
    "           time=df['10 uM'].dropna().values.astype(float))\n",
    "data14 = dict(N=len(df['14 uM'].dropna()),\n",
    "           time=df['14 uM'].dropna().values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples12 = sm2.sampling(data=data12)\n",
    "samples7 = sm2.sampling(data=data7)\n",
    "samples9 = sm2.sampling(data=data9)\n",
    "samples10 = sm2.sampling(data=data10)\n",
    "samples14 = sm2.sampling(data=data14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now preform post predictive checks and can conlcude that the gamma model is resoanble for all 5 concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples12, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['12 uM'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False,\n",
    "                                          title = \"12 uM\",\n",
    "                                          x_axis_label = \"intercatastrophe time (s)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples7, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['7 uM'].dropna().values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False,\n",
    "                                          title = \"7 uM\",\n",
    "                                          x_axis_label = \"intercatastrophe time (s)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples9, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['9 uM'].dropna().values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False,\n",
    "                                          title = \"9 uM\",\n",
    "                                          x_axis_label = \"intercatastrophe time (s)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples10, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['10 uM'].dropna().values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False,\n",
    "                                          title = \"10 uM\",\n",
    "                                          x_axis_label = \"intercatastrophe time (s)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples14, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='time_ppc', \n",
    "                                          data=df['14 uM'].dropna().values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False,\n",
    "                                          title = \"14 uM\",\n",
    "                                          x_axis_label = \"intercatastrophe time (s)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to examine the occurrence of catastrophe by looking at the values of the parameters versus tubulin concentration?\n",
    "\n",
    "There are two parameters for this distribution,  ð¼  and  ð½ , where  ð¼  is the number of arrivals (or \"steps\") required to trigger catastrophe, and  ð½  is the rate of the arrivals. Thus, the characteristic catastrophe time is given by  ð¼/ð½ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to put our sampled values in a dataframe so we can look at the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc7 = bebi103.stan.to_dataframe(samples7, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc9 = bebi103.stan.to_dataframe(samples9, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc10 = bebi103.stan.to_dataframe(samples10, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc12 = bebi103.stan.to_dataframe(samples12, diagnostics=False, inc_warmup=False)\n",
    "df_mcmc14 = bebi103.stan.to_dataframe(samples14, diagnostics=False, inc_warmup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a column labeling each dataframe for ease of plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc7[\"Concentration\"] = 7\n",
    "df_mcmc9[\"Concentration\"] = 9\n",
    "df_mcmc10[\"Concentration\"] = 10\n",
    "df_mcmc12[\"Concentration\"] = 12\n",
    "df_mcmc14[\"Concentration\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the ð¼ values for each concentration. This will give us an idea of the amount of steps required to trigger catastrophe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's make a helper plotting function\n",
    "def make_ecdf(dataframe, data, title):\n",
    "    c = altcat.catplot(data=dataframe,\n",
    "               mark='line',\n",
    "               encoding=dict(x=alt.X(data,\n",
    "                                     scale=alt.Scale(\n",
    "                                           clamp=True)),\n",
    "                            color = alt.Color(\"Concentration\")),\n",
    "               transform='ecdf'\n",
    "              ).properties(height=300,\n",
    "                           width=300,\n",
    "                           title = title)\n",
    "    return c\n",
    "\n",
    "# Now let's plot\n",
    "(make_ecdf(df_mcmc7, \"alpha_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc9, \"alpha_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc10, \"alpha_:Q\", \"All Experiments\")\n",
    "+ make_ecdf(df_mcmc12, \"alpha_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc14, \"alpha_:Q\", \"All Experiments\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general ð¼ appears to increase with increasing concentration, although this is not true for concentration 12. This indicates that with higher concentration, it takes more steps to trigger catastrophe. Let's print the average alpha for each concentration for good measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_7 = df_mcmc7[\"alpha_\"].mean() \n",
    "a_9 = df_mcmc9[\"alpha_\"].mean() \n",
    "a_10 = df_mcmc10[\"alpha_\"].mean()\n",
    "a_12 = df_mcmc12[\"alpha_\"].mean() \n",
    "a_14 = df_mcmc14[\"alpha_\"].mean() \n",
    "\n",
    "{\"7\" : a_7, \"9\" : a_9, \"10\" : a_10, \"12\" : a_12, \"14\" : a_14}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(make_ecdf(df_mcmc7, \"beta_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc9, \"beta_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc10, \"beta_:Q\", \"All Experiments\")\n",
    "+ make_ecdf(df_mcmc12, \"beta_:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc14, \"beta_:Q\", \"All Experiments\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_7 = df_mcmc7[\"beta_\"].mean() \n",
    "b_9 = df_mcmc9[\"beta_\"].mean() \n",
    "b_10 = df_mcmc10[\"beta_\"].mean() \n",
    "b_12 = df_mcmc12[\"beta_\"].mean() \n",
    "b_14 = df_mcmc14[\"beta_\"].mean() \n",
    "\n",
    "{\"7\" : b_7, \"9\" : b_9, \"10\" : b_10, \"12\" : b_12, \"14\" : b_14}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the characteristic catastrophe time (given by  ð¼/ð½ ) for each concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcmc7[\"alpha/beta\"] = df_mcmc7[\"alpha_\"] / df_mcmc7[\"beta_\"]\n",
    "df_mcmc9[\"alpha/beta\"] = df_mcmc9[\"alpha_\"] / df_mcmc9[\"beta_\"]\n",
    "df_mcmc10[\"alpha/beta\"] = df_mcmc10[\"alpha_\"] / df_mcmc10[\"beta_\"]\n",
    "df_mcmc12[\"alpha/beta\"] = df_mcmc12[\"alpha_\"] / df_mcmc12[\"beta_\"]\n",
    "df_mcmc14[\"alpha/beta\"] = df_mcmc14[\"alpha_\"] / df_mcmc14[\"beta_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(make_ecdf(df_mcmc7, \"alpha/beta:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc9, \"alpha/beta:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc10, \"alpha/beta:Q\", \"All Experiments\")\n",
    "+ make_ecdf(df_mcmc12, \"alpha/beta:Q\", \"All Experiments\") \n",
    "+ make_ecdf(df_mcmc14, \"alpha/beta:Q\", \"All Experiments\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As concentration increases, the characteristic catastrophe time seems to generally increase (the 9uM data breaks this trend). This makes sense given that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_7 = df_mcmc7[\"alpha/beta\"].mean() \n",
    "ab_9 = df_mcmc9[\"alpha/beta\"].mean() \n",
    "ab_10 = df_mcmc10[\"alpha/beta\"].mean() \n",
    "ab_12 = df_mcmc12[\"alpha/beta\"].mean() \n",
    "ab_14 = df_mcmc14[\"alpha/beta\"].mean() \n",
    "\n",
    "{\"7\" : ab_7, \"9\" : ab_9, \"10\" : ab_10, \"12\" : ab_12, \"14\" : ab_14}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will print out all the model / prior predictive check code for your viewing pleasure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------MODEL CHECK 1-------------\")\n",
    "print(prior_sm1.model_code)\n",
    "print(\"-------------MODEL CHECK 2-------------\")\n",
    "print(prior_sm2.model_code)\n",
    "print(\"-------------MODEL CHECK 3-------------\")\n",
    "print(prior_sm3.model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------MODEL 1-------------\")\n",
    "print(sm1.model_code)\n",
    "print(\"-------------MODEL 2-------------\")\n",
    "print(sm2.model_code)\n",
    "print(\"-------------MODEL 3-------------\")\n",
    "print(sm3.model_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
